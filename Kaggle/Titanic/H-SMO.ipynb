{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMO implementation\n",
    "Attempting to implement the SMO (https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tr-98-14.pdf). \n",
    "\n",
    "Also consider https://www.csie.ntu.edu.tw/~cjlin/papers/bottou_lin.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step, we wil need to be able to evaluate the SVM on\n",
    "a single instance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I initially explored hmatrix, but then I realised that I don't need matrix inversion for this algorithm, so using Repa would be better\n",
    "`--import Numeric.LinearAlgebra`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "{- LANGUAGE XTypeOperators -}\n",
    "{-# LANGUAGE TemplateHaskell #-}\n",
    "import Control.Lens\n",
    "import  Data.Array.Repa\n",
    "import qualified Data.Array.Repa as R\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import Data.Array.Repa.Repr.Vector\n",
    "import qualified Data.Vector as V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import Data.Array.Repa.Repr.Vector                   as RV\n",
    "import Data.Array.Repa.Algorithms.Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type Value = Double\n",
    "\n",
    "type BaseVector = Array U DIM1 Value\n",
    "type BaseScalar = Array U Z Value\n",
    "\n",
    "-- Making these types to attempt to make the system more type-safe\n",
    "data Sample = Sample BaseVector deriving (Show)\n",
    "data Weights = Weights BaseVector deriving (Show)\n",
    "\n",
    "weightAsSample :: Weights -> Sample\n",
    "weightAsSample (Weights w) = Sample w\n",
    "\n",
    "type Threshold = BaseScalar\n",
    "\n",
    "-- There is probably an opportunity to build a type-class around the \n",
    "-- rules for composing kernel functions. \n",
    "type Kernel = Sample -> Sample -> BaseScalar\n",
    "\n",
    "data ClassLabel = Class1 | Class2 deriving (Show, Eq)\n",
    "\n",
    "-- An SVM prediction also contains the \"margin\" that can be useful for solving\n",
    "data PredictedLabel = PredictClass1 Value | PredictClass2 Value deriving (Show, Eq)\n",
    "\n",
    "\n",
    "\n",
    "data SupportVector = SupportVector {\n",
    "                         _alpha :: BaseScalar\n",
    "                       , _vector :: Sample \n",
    "                       } deriving (Show)\n",
    "                       \n",
    "data TrainingSupportVector = TrainingSV {\n",
    "                             _trueLabel :: ClassLabel\n",
    "                           , _predLabel :: PredictedLabel\n",
    "                           , _classError :: Value\n",
    "                           , _supvec :: SupportVector\n",
    "                        } deriving (Show)\n",
    "\n",
    "data SVMParameters = SVMParameters {\n",
    "                        _kernel :: Kernel\n",
    "                     ,  _threshold :: Threshold\n",
    "                     ,  _margin :: BaseScalar     -- parameter C in eq. 9\n",
    "                     ,  _epsillon :: Value        -- rounding error for equality\n",
    "                    } \n",
    "\n",
    "data TrainingData = TrainingData {_training :: V.Vector TrainingSupportVector}\n",
    "\n",
    "makeLenses ''SupportVector\n",
    "makeLenses ''TrainingSupportVector\n",
    "makeLenses ''SVMParameters\n",
    "makeLenses ''TrainingData\n",
    "\n",
    "getVec a = a^.(supvec . vector)\n",
    "getAlpha a = a^. (supvec . alpha) \n",
    "\n",
    "\n",
    "\n",
    "-- PredictedLabel helpers\n",
    "\n",
    "getLabelValue :: PredictedLabel -> Value\n",
    "getLabelValue (PredictClass1 v) = v\n",
    "getLabelValue (PredictClass2 v) = v\n",
    "\n",
    "predictToTrue :: PredictedLabel -> ClassLabel\n",
    "predictToTrue (PredictClass1 _) = Class1\n",
    "predictToTrue (PredictClass2 _) = Class2\n",
    "\n",
    "wrapScalar :: Value -> BaseScalar\n",
    "wrapScalar s = fromListUnboxed Z ([s] :: [Value])\n",
    "\n",
    "-- Building an SVM\n",
    "\n",
    "chooseClass :: Value -> PredictedLabel\n",
    "chooseClass res = if res >= 0 then PredictClass1 res else PredictClass2 res\n",
    "             \n",
    "dot :: Kernel\n",
    "dot (Sample a) (Sample b) = foldS (+) 0 ( a *^ b) \n",
    "\n",
    "\n",
    "evaluateKernelWithWeight :: Kernel -> SupportVector -> Sample -> BaseScalar\n",
    "evaluateKernelWithWeight k sv x = computeS $ (sv^.alpha) *^ (sv^.vector) `k` x \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svm :: SVMParameters -> [SupportVector] -> Sample -> PredictedLabel\n",
    "svm params svl x = \n",
    "              let\n",
    "                k = params^.kernel\n",
    "                b = params^.threshold\n",
    "                res = foldl (\\a sv -> computeS (a +^ evaluateKernelWithWeight k sv x) ) (wrapScalar 0) svl -^ b\n",
    "              in \n",
    "                chooseClass $ res ! Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictClass1 1868.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_inputs = [1..10] :: [Value]\n",
    "w_inputs = [11..20] :: [Value]\n",
    "x = Sample $ fromListUnboxed (Z :. (10::Int))  x_inputs\n",
    "w = Sample $ fromListUnboxed (Z :. (10::Int))  w_inputs\n",
    "\n",
    "thresh = wrapScalar 2 \n",
    "params = SVMParameters {_kernel=dot, _threshold=thresh, _margin=thresh}\n",
    "\n",
    "svl = [SupportVector thresh w]\n",
    "svm params svl x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictClass2 (-98130.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "largethresh = wrapScalar 100000\n",
    "largerParams = SVMParameters {_kernel=dot, _threshold=largethresh, _margin=thresh}\n",
    "\n",
    "svm largerParams svl x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Helper Functions \n",
    "Now that we can evaluate the SVM we need to work towards building the simple functions described in the paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- Make a scalar multiplication operator\n",
    "--(.*) :: Value -> BaseScalar -> BaseScalar\n",
    "--(.*) val vec = R.computeUnboxedS $ R.map (\\x -> val*x) vec\n",
    "\n",
    "-- equation 15, 2nd Derivative\n",
    "calcGrad :: Kernel -> Sample -> Sample -> BaseScalar\n",
    "calcGrad k x1 x2 =  computeS $ (x1 `k` x1) +^ (x2 `k` x2) -^ (wrapScalar 2 *^ (x1 `k` x2) )\n",
    "\n",
    "calcEta :: SVMParameters -> TrainingSupportVector -> TrainingSupportVector -> BaseScalar\n",
    "calcEta params sv1 sv2 =\n",
    "    calcGrad (params^.kernel) (sv1^.supvec.vector) (sv2^.supvec.vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>/* Styles used for the Hoogle display in the pager */\n",
       ".hoogle-doc {\n",
       "display: block;\n",
       "padding-bottom: 1.3em;\n",
       "padding-left: 0.4em;\n",
       "}\n",
       ".hoogle-code {\n",
       "display: block;\n",
       "font-family: monospace;\n",
       "white-space: pre;\n",
       "}\n",
       ".hoogle-text {\n",
       "display: block;\n",
       "}\n",
       ".hoogle-name {\n",
       "color: green;\n",
       "font-weight: bold;\n",
       "}\n",
       ".hoogle-head {\n",
       "font-weight: bold;\n",
       "}\n",
       ".hoogle-sub {\n",
       "display: block;\n",
       "margin-left: 0.4em;\n",
       "}\n",
       ".hoogle-package {\n",
       "font-weight: bold;\n",
       "font-style: italic;\n",
       "}\n",
       ".hoogle-module {\n",
       "font-weight: bold;\n",
       "}\n",
       ".hoogle-class {\n",
       "font-weight: bold;\n",
       "}\n",
       ".get-type {\n",
       "color: green;\n",
       "font-weight: bold;\n",
       "font-family: monospace;\n",
       "display: block;\n",
       "white-space: pre-wrap;\n",
       "}\n",
       ".show-type {\n",
       "color: green;\n",
       "font-weight: bold;\n",
       "font-family: monospace;\n",
       "margin-left: 1em;\n",
       "}\n",
       ".mono {\n",
       "font-family: monospace;\n",
       "display: block;\n",
       "}\n",
       ".err-msg {\n",
       "color: red;\n",
       "font-style: italic;\n",
       "font-family: monospace;\n",
       "white-space: pre;\n",
       "display: block;\n",
       "}\n",
       "#unshowable {\n",
       "color: red;\n",
       "font-weight: bold;\n",
       "}\n",
       ".err-msg.in.collapse {\n",
       "padding-top: 0.7em;\n",
       "}\n",
       ".highlight-code {\n",
       "white-space: pre;\n",
       "font-family: monospace;\n",
       "}\n",
       ".suggestion-warning { \n",
       "font-weight: bold;\n",
       "color: rgb(200, 130, 0);\n",
       "}\n",
       ".suggestion-error { \n",
       "font-weight: bold;\n",
       "color: red;\n",
       "}\n",
       ".suggestion-name {\n",
       "font-weight: bold;\n",
       "}\n",
       "</style><span class='err-msg'>Not in scope: `eta'</span>"
      ],
      "text/plain": [
       "Not in scope: `eta'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eta dot x x -- should equal zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "classToDbl ::  ClassLabel -> Value\n",
    "classToDbl Class1 = 1\n",
    "classToDbl Class2 = -1\n",
    "\n",
    "classToScalar :: ClassLabel -> BaseScalar\n",
    "classToScalar a = wrapScalar $ classToDbl a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "calcClassError :: ClassLabel -> PredictedLabel -> Value\n",
    "calcClassError trueLabel predLabel =\n",
    "    let\n",
    "        predClass = predictToTrue predLabel\n",
    "        predVal = getLabelValue predLabel\n",
    "        classVal = classToDbl trueLabel\n",
    "    in\n",
    "        --if trueLabel == predClass then 0 else predVal - classVal\n",
    "        predVal - classVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- equation 16, minimum along contstraint direction\n",
    "alpha2New :: BaseScalar -- Result of gradient calculation\n",
    "             -> TrainingSupportVector -- Training Point 1\n",
    "             -> TrainingSupportVector -- Training Point 2\n",
    "             -> BaseScalar -- New alpha2            \n",
    "alpha2New e sv1 sv2 = -- a e y1 y2 s1 s2 = \n",
    "    let \n",
    "        y2 = wrapScalar $ classToDbl $ sv2^.trueLabel     \n",
    "        e1 = sv1^.classError\n",
    "        e2 = sv2^.classError\n",
    "        diff = wrapScalar $ e1 - e2\n",
    "        a = sv2^.supvec.alpha\n",
    "    in\n",
    "       computeS $ a  +^ y2 *^ diff /^ e -- Implementing eq 16\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- Equation 17, \n",
    "alphaNewClipped :: (Num a, Ord a) => a -- alpha2New \n",
    "                   -> a                -- H\n",
    "                   -> a                -- L\n",
    "                   -> a\n",
    "alphaNewClipped a h l \n",
    "    | a >= h = h \n",
    "    | a <= l = l\n",
    "    | otherwise = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scalarToDbl :: BaseScalar -> Value\n",
    "scalarToDbl s = s ! ( Z )\n",
    "\n",
    "calcS :: ClassLabel -> ClassLabel -> Value\n",
    "calcS y1 y2 =\n",
    "    classToDbl y1 * classToDbl y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- Equation 18\n",
    "\n",
    "alpha1New :: TrainingSupportVector     -- Sample 1\n",
    "            -> TrainingSupportVector  -- Sample 2\n",
    "            -> BaseScalar             -- New alpha2\n",
    "            -> BaseScalar             -- New alpha2clipped\n",
    "            -> BaseScalar\n",
    "alpha1New sv1 sv2 a2 a2clip =\n",
    "    let \n",
    "        s = wrapScalar $ calcS (sv1^.trueLabel) (sv2^.trueLabel)\n",
    "        a = sv1^.supvec.alpha\n",
    "    in \n",
    "        computeS $ a +^ s *^ (a2 -^ a2clip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Equation 19 has a rediculous number of equations!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f1 :: SVMParameters  -- SVM Parameters\n",
    "      -> TrainingSupportVector -- Vector1\n",
    "      -> TrainingSupportVector -- vector2\n",
    "      -> BaseScalar\n",
    "f1 params sv1 sv2 =\n",
    "    let\n",
    "        k = params^.kernel\n",
    "        b = params^.threshold\n",
    "        a1 = sv1^.supvec.alpha\n",
    "        a2 = sv2^.supvec.alpha\n",
    "        y1 = sv1^.trueLabel\n",
    "        y1' = wrapScalar $ classToDbl y1\n",
    "        y2 = sv2^.trueLabel\n",
    "        x1 = sv1^.supvec.vector\n",
    "        x2 = sv2^.supvec.vector\n",
    "        s   = wrapScalar $ calcS y1 y2\n",
    "        k11 = x1 `k` x1\n",
    "        k12 = x1 `k` x2\n",
    "        e1 = wrapScalar $ calcClassError (sv1^.trueLabel) (sv1^.predLabel)\n",
    "    in\n",
    "        computeS $ y1'*^ (e1 +^ b) -^  a1 *^ k11 -^ s *^ a2 *^ k12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f2 :: SVMParameters -- \n",
    "      -> TrainingSupportVector -- Vector1\n",
    "      -> TrainingSupportVector -- vector2\n",
    "      -> BaseScalar\n",
    "f2 params sv1 sv2 =\n",
    "    let\n",
    "        k = params^.kernel\n",
    "        b = params^.threshold\n",
    "        a1 = sv1^.supvec.alpha\n",
    "        a2 = sv2^.supvec.alpha\n",
    "        y1 = sv1^.trueLabel\n",
    "        y1'= wrapScalar $ classToDbl y1\n",
    "        y2 = sv2^.trueLabel\n",
    "        y2'= wrapScalar $ classToDbl y2\n",
    "        x1 = sv1^.supvec.vector\n",
    "        x2 = sv2^.supvec.vector\n",
    "        s   = wrapScalar $ calcS y1 y2\n",
    "        k22 = x2 `k` x2\n",
    "        k12 = x1 `k` x2\n",
    "        e2 = wrapScalar $ calcClassError (sv2^.trueLabel) (sv2^.predLabel)\n",
    "    in\n",
    "        computeS $ y2'*^(e2 +^ b) -^ s *^ a1 *^ k12 -^ a2 *^ k22\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- equation 13\n",
    "lowerAlpha :: SVMParameters \n",
    "              -> TrainingSupportVector\n",
    "              -> TrainingSupportVector\n",
    "              -> Value\n",
    "lowerAlpha params sv1 sv2 =\n",
    "    let \n",
    "        y1 = sv1^.trueLabel\n",
    "        y2 = sv2^.trueLabel\n",
    "        a1 = scalarToDbl $ sv1^.supvec.alpha\n",
    "        a2 = scalarToDbl $ sv2^.supvec.alpha\n",
    "        c = scalarToDbl $ params^.margin\n",
    "    in\n",
    "        if not(y1 == y2) \n",
    "        then\n",
    "            max 0 (a1 - a2)\n",
    "        else\n",
    "            max 0 (a1 - a2 - c)\n",
    "            \n",
    "\n",
    "-- equation 14\n",
    "upperAlpha :: SVMParameters \n",
    "              -> TrainingSupportVector\n",
    "              -> TrainingSupportVector\n",
    "              -> Value\n",
    "upperAlpha params sv1 sv2 =\n",
    "    let \n",
    "        y1 = sv1^.trueLabel\n",
    "        y2 = sv2^.trueLabel\n",
    "        a1 = scalarToDbl $ sv1^.supvec.alpha\n",
    "        a2 = scalarToDbl $ sv2^.supvec.alpha\n",
    "        c = scalarToDbl $ params^.margin\n",
    "    in\n",
    "        if not (y1 == y2)\n",
    "        then\n",
    "            min c (c + a1 - a2)\n",
    "        else\n",
    "            min c (a1 - a2)\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l1 :: SVMParameters\n",
    "      -> TrainingSupportVector  -- sample1\n",
    "      -> TrainingSupportVector -- sample2\n",
    "      -> Value\n",
    "l1 params sv1 sv2 =\n",
    "    let\n",
    "        y1 = sv1^.trueLabel\n",
    "        y2 = sv2^.trueLabel\n",
    "        a1 = scalarToDbl $ sv1^.supvec.alpha\n",
    "        a2 = scalarToDbl $ sv2^.supvec.alpha\n",
    "        c = scalarToDbl $ params^.margin\n",
    "        l = lowerAlpha params sv1 sv2\n",
    "        s = calcS y1 y2\n",
    "    in\n",
    "        a1 + s * (a2 - l)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h1 :: SVMParameters\n",
    "      -> TrainingSupportVector  -- sample1\n",
    "      -> TrainingSupportVector -- sample2\n",
    "      -> Value\n",
    "h1 params sv1 sv2 =\n",
    "    let\n",
    "        y1 = sv1^.trueLabel\n",
    "        y2 = sv2^.trueLabel\n",
    "        a1 = scalarToDbl $ sv1^.supvec.alpha\n",
    "        a2 = scalarToDbl $ sv2^.supvec.alpha\n",
    "        c = scalarToDbl $ params^.margin\n",
    "        h = upperAlpha params sv1 sv2\n",
    "        s = calcS y1 y2\n",
    "    in\n",
    "        a1 + s * (a2 - h)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "psiLower :: SVMParameters\n",
    "            -> TrainingSupportVector -- Sample1\n",
    "            -> TrainingSupportVector -- Sample2\n",
    "            -> BaseScalar\n",
    "psiLower params sv1 sv2 = --a1 a2 y1 y2 x1 x2 t1 t2 l =\n",
    "    let\n",
    "        k = params^.kernel\n",
    "        b = params^.threshold\n",
    "        y1 = sv1^.trueLabel\n",
    "        y2 = sv2^.trueLabel\n",
    "        x1 = sv1^.supvec.vector\n",
    "        x2 = sv2^.supvec.vector\n",
    "        f1' = f1 params sv1 sv2 \n",
    "        f2' = f2 params sv1 sv2 \n",
    "        l1' = wrapScalar $ l1 params sv1 sv2\n",
    "        l' = wrapScalar $ lowerAlpha params sv1 sv2\n",
    "        s = wrapScalar $ calcS y1 y2\n",
    "        k11 = x1 `k` x1\n",
    "        k12 = x1 `k` x2\n",
    "        k22 = x2 `k` x2\n",
    "        half = wrapScalar 0.5\n",
    "    in\n",
    "       computeS $ l1'*^f1' \n",
    "           +^ l'*^f2' \n",
    "           +^ half*^l1'*^l1'*^k11 \n",
    "           +^ half*^l1'*^l1'*^k22 \n",
    "           +^ s*^l'*^l1'*^k12\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "psiUpper :: SVMParameters \n",
    "            -> TrainingSupportVector -- Sample1\n",
    "            -> TrainingSupportVector -- Sample2\n",
    "            -> BaseScalar\n",
    "psiUpper params sv1 sv2= \n",
    "    let\n",
    "        b = params^.threshold\n",
    "        k = params^.kernel\n",
    "        a1 = sv1^.supvec.alpha\n",
    "        a2 = sv2^.supvec.alpha\n",
    "        y1 = sv1^.trueLabel\n",
    "        y2 = sv2^.trueLabel\n",
    "        x1 = sv1^.supvec.vector\n",
    "        x2 = sv2^.supvec.vector\n",
    "        f1' = f1 params sv1 sv2\n",
    "        f2' = f2 params sv1 sv2\n",
    "        h1' = wrapScalar $ h1 params sv1 sv2\n",
    "        h' = wrapScalar $ upperAlpha params sv1 sv2\n",
    "        s = wrapScalar $ calcS y1 y2\n",
    "        k11 = x1 `k` x1\n",
    "        k12 = x1 `k` x2\n",
    "        k22 = x2 `k` x2\n",
    "        half = wrapScalar 0.5\n",
    "    in\n",
    "        computeS $ h1'*^f1' +^ h'*^f2' \n",
    "                +^ half *^ h1' *^ h1' *^ k11 \n",
    "                +^ half *^ h1' *^ h1' *^ k22\n",
    "                +^ s *^ h' *^ h1' *^ k12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to implement eq 20 and 21 for calculating threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compareWithEps :: Value -> Value -> Value -> Bool\n",
    "compareWithEps eps a b = \n",
    "    if abs (a - b) <= eps then True else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "determineAtBound :: Value -> Value -> Value -> Bool\n",
    "determineAtBound eps c a = \n",
    "    let\n",
    "        upper = compareWithEps eps c a\n",
    "        zero = compareWithEps eps 0 a\n",
    "    in\n",
    "        case (upper, zero) of\n",
    "            (False, False) -> False\n",
    "            otherwise -> True\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "computeB :: SVMParameters\n",
    "        -> Value -- alpha1new\n",
    "        -> Value -- alpha2newclipped\n",
    "        -> TrainingSupportVector -- support vector 1\n",
    "        -> TrainingSupportVector -- support vector 2\n",
    "        -> Value\n",
    "computeB params a1new a2new sv1 sv2 =\n",
    "    let\n",
    "        eps = params^.epsillon\n",
    "        c = scalarToDbl $ params^.margin\n",
    "        k = params^.kernel\n",
    "        b = params^.threshold\n",
    "        y1 = sv1^.trueLabel\n",
    "        y2 = sv2^.trueLabel\n",
    "        t1 = sv1^.predLabel\n",
    "        t2 = sv2^.predLabel\n",
    "        x1 = sv1^.supvec.vector\n",
    "        x2 = sv2^.supvec.vector\n",
    "        a1 = scalarToDbl (sv1^.supvec.alpha) \n",
    "        a2 = scalarToDbl (sv2^.supvec.alpha) \n",
    "        \n",
    "        b' = scalarToDbl b\n",
    "        y1' = classToDbl y1\n",
    "        y2' = classToDbl y2\n",
    "        e1 = calcClassError y1 t1\n",
    "        e2 = calcClassError y2 t2\n",
    "        k11 = scalarToDbl $ k x1 x1\n",
    "        k12 = scalarToDbl $ k x1 x2\n",
    "        k22 = scalarToDbl $ k x2 x2\n",
    "        \n",
    "        b1 = e1 + y1'*(a1new - a1)*k11 \n",
    "                + y2'*(a2new - a2)*k12 + b'\n",
    "                \n",
    "        b2 = e2 + y1'*(a1new - a1)*k12\n",
    "                + y2'*(a2new-a2)*k22 + b'\n",
    "        a1atBound = determineAtBound eps c a1new\n",
    "        a2atBound = determineAtBound eps c a2new\n",
    "     \n",
    "    in\n",
    "        case (a1atBound, a2atBound) of\n",
    "            (True, True) -> (b1+b2)/2\n",
    "            (False, True) -> b2\n",
    "            (True, False) -> b1\n",
    "            (False, False) -> b1 -- (Note b1 should equal b2 in this instance?)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement Procedures\n",
    "Now that we have the basic building blocks, we should be able to implement the procedures in section 2.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "elementDifference :: Sample -> Sample -> BaseVector\n",
    "elementDifference (Sample v1) (Sample v2) =\n",
    "    computeS $ (v1 -^ v2)\n",
    "    \n",
    "sumVector :: BaseVector -> Value\n",
    "sumVector v =\n",
    "    foldAllS (+) 0 v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "etaOutOfBounds :: SVMParameters\n",
    "                    -> TrainingSupportVector\n",
    "                    -> TrainingSupportVector\n",
    "                    -> Value\n",
    "etaOutOfBounds params sv1 sv2 =\n",
    "    let\n",
    "       eps = params^.epsillon\n",
    "       alpha2 = scalarToDbl $ sv2^.supvec.alpha\n",
    "       h_obj = scalarToDbl $ psiUpper params sv1 sv2\n",
    "       l_obj = scalarToDbl $ psiLower params sv1 sv2\n",
    "       l = l1 params sv1 sv2\n",
    "       h = h1 params sv1 sv2\n",
    "    in\n",
    "        if l_obj < h_obj - eps then l\n",
    "        else\n",
    "            if l_obj > h_obj + eps then h\n",
    "            else alpha2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- This function determines what alpha2 should be but can fail. \n",
    "determineAlpha2 :: SVMParameters\n",
    "                   -> TrainingSupportVector\n",
    "                   -> TrainingSupportVector\n",
    "                   -> Maybe (Value, Value)\n",
    "determineAlpha2 params sv1 sv2 =\n",
    "    let\n",
    "        eps = params^.epsillon\n",
    "        eta = calcEta params sv1 sv2\n",
    "        l =  l1 params sv1 sv2\n",
    "        h =  h1 params sv1 sv2\n",
    "        alpha1 = scalarToDbl $ sv1^.supvec.alpha\n",
    "        alpha2 = scalarToDbl $ sv2^.supvec.alpha\n",
    "        a2clip = alphaNewClipped a2' h l\n",
    "        outOfBounds = etaOutOfBounds params sv1 sv2\n",
    "        a2' = scalarToDbl $ alpha2New eta sv1 sv2\n",
    "        a2 = if scalarToDbl (eta) > 0 then a2clip else outOfBounds                   \n",
    "    in \n",
    "     do \n",
    "       _ <- if (abs(a2-alpha2) < eps*(a2+alpha2+eps)) then Nothing else Just ()\n",
    "       Just (a2, a2clip)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainToSv :: V.Vector TrainingSupportVector -> V.Vector Sample\n",
    "trainToSv = V.map (\\a -> a^.supvec.vector )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- modify existing training vector\n",
    "constructTrainingVec :: TrainingSupportVector\n",
    "                        -> PredictedLabel\n",
    "                        -> SupportVector\n",
    "                        -> TrainingSupportVector\n",
    "constructTrainingVec tsv label sv =\n",
    "    let \n",
    "        trueL = tsv^.trueLabel\n",
    "        err = calcClassError trueL label\n",
    "    in\n",
    "        TrainingSV \n",
    "            {\n",
    "              _trueLabel = trueL\n",
    "            , _predLabel = label\n",
    "            , _supvec = sv\n",
    "            , _classError = err\n",
    "            }\n",
    "\n",
    "\n",
    "-- Assume that training support vector aren't equal.\n",
    "takeStep :: SVMParameters \n",
    "            -> V.Vector TrainingSupportVector\n",
    "            -> Int  -- Index into trainData for i\n",
    "            -> Int  -- Index into trainData for j\n",
    "            -> Maybe (TrainingSupportVector, TrainingSupportVector)\n",
    "takeStep params tData i j =\n",
    "    let\n",
    "        sv1 = tData V.! ( i)\n",
    "        sv2 = tData V.! ( j)\n",
    "        x1 = sv1^.supvec.vector\n",
    "        x2 = sv2^.supvec.vector\n",
    "        diff = sumVector (elementDifference x1 x2)\n",
    "        identical = abs (diff) < params^.epsillon\n",
    "        sVectors = V.map (\\a-> a^.supvec) tData\n",
    "    in\n",
    "        do \n",
    "            -- First step, check that the vectors are identical. \n",
    "            _ <- pure (if identical then Nothing else Just ())\n",
    "            (a2, a2clip) <- determineAlpha2 params sv1 sv2\n",
    "            a1 <- pure $ alpha1New sv1 sv2 (wrapScalar a2) (wrapScalar a2clip)\n",
    "            sv1' <- pure $ SupportVector {_alpha= a1, _vector=sv1^.supvec.vector}\n",
    "            sv2' <- pure $ SupportVector {_alpha=wrapScalar (a2), _vector=sv2^.supvec.vector}\n",
    "            newSvec <- pure $ V.toList $ sVectors V.// [(i, sv1'), (j, sv2')]\n",
    "            pred1 <- pure $ svm params newSvec x1\n",
    "            pred2 <- pure $ svm params newSvec x2\n",
    "            finalSv1 <- pure $ constructTrainingVec sv1 pred1 sv1'\n",
    "            finalSv2 <- pure $ constructTrainingVec sv2 pred2 sv2'\n",
    "            -- Next evaluate SVM using the new results for a1 and a2\n",
    "            -- Looks like I will need a complete SVM copy, and to make a\n",
    "            -- new training set... can I build a traverse?\n",
    "            return (finalSv1, finalSv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Haskell",
   "language": "haskell",
   "name": "haskell"
  },
  "language_info": {
   "codemirror_mode": "ihaskell",
   "file_extension": ".hs",
   "name": "haskell",
   "version": "7.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
